{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T13:02:03.082250Z",
     "start_time": "2020-08-16T13:02:03.071181Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.spatial.distance import euclidean, cityblock\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T13:04:26.737605Z",
     "start_time": "2020-08-16T13:04:26.669929Z"
    }
   },
   "outputs": [],
   "source": [
    "df_clean = df_cleaned = pd.read_pickle('../data_cleaning/clusters_added.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T12:41:56.254297Z",
     "start_time": "2020-08-16T12:41:56.249988Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-13T14:20:12.143183Z",
     "start_time": "2020-08-13T14:20:12.140070Z"
    }
   },
   "source": [
    "### Vectorization and IDF scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T12:55:14.667199Z",
     "start_time": "2020-08-16T12:55:13.721224Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english', min_df=0.001, max_df=0.999).fit(bills['combined_title'])\n",
    "X_idf  = tfidf.transform(bills['combined_title']).toarray()\n",
    "X_feat_names = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T12:55:15.475299Z",
     "start_time": "2020-08-16T12:55:15.465480Z"
    }
   },
   "outputs": [],
   "source": [
    "def nearest_k(query, objects, k, dist):\n",
    "    \"\"\"Return the indices to objects most similar to query\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    query : ndarray\n",
    "        query object represented in the same form vector representation as the\n",
    "        objects\n",
    "    objects : ndarray\n",
    "        vector-represented objects in the database; rows correspond to \n",
    "        objects, columns correspond to features\n",
    "    k : int\n",
    "        number of most similar objects to return\n",
    "    dist : function\n",
    "        accepts two ndarrays as parameters then returns their distance\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        Indices to the most similar objects in the database\n",
    "    \"\"\"\n",
    "    return np.argsort([dist(query, o) for o in objects])[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T13:13:25.214474Z",
     "start_time": "2020-08-16T13:13:25.196825Z"
    }
   },
   "outputs": [],
   "source": [
    "def inverse_transform(text_query):\n",
    "    \"\"\"Codes copied from data_building_and_cleaning. Credits to the \n",
    "    rightful owner.\"\"\"\n",
    "    \n",
    "    import string\n",
    "    punc = string.punctuation.replace('-', '').replace(\"'\", '')\n",
    "    table = str.maketrans(' ', ' ', punc)\n",
    "    stripped = [w.translate(table) for w in [text_query.lower()]]\n",
    "\n",
    "    ######################################################################\n",
    "\n",
    "    # filter out stop words\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    no_stop_words = []\n",
    "    for word_list in stripped:\n",
    "        word_list = word_list.split()\n",
    "        words = [w for w in word_list if not w in stop_words]\n",
    "        no_stop_words += [words]\n",
    "\n",
    "    ######################################################################\n",
    "\n",
    "    # nltk.download('wordnet')\n",
    "    from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "    lematized = []\n",
    "    for word_list in no_stop_words:\n",
    "        words = [lemmatizer.lemmatize(w) for w in word_list]\n",
    "        lematized += [words]\n",
    "\n",
    "    title_cleaned = []\n",
    "    for i in lematized:\n",
    "        title_cleaned+=[\" \".join(i)]\n",
    "\n",
    "    return title_cleaned[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T13:13:28.586869Z",
     "start_time": "2020-08-16T13:13:28.572012Z"
    }
   },
   "outputs": [],
   "source": [
    "text_query = 'education coffee'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T13:13:29.118475Z",
     "start_time": "2020-08-16T13:13:28.727406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "education coffee\n"
     ]
    }
   ],
   "source": [
    "## sample querying\n",
    "\n",
    "query = [lemmatizer.lemmatize(inverse_transform(text_query))]\n",
    "\n",
    "# no of results\n",
    "k = 5\n",
    "                              \n",
    "print(query[0])\n",
    "                              \n",
    "search_results = nearest_k(tfidf.transform(query).toarray()[0], X_idf, k, euclidean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T13:13:29.261805Z",
     "start_time": "2020-08-16T13:13:29.246308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 search results:\n",
      "\n",
      "\n",
      "Top 1\n",
      " PREPARATORY EDUCATION ACT \n",
      "\n",
      "Top 2\n",
      " PRESCHOOL EDUCATION ACT \n",
      "\n",
      "Top 3\n",
      " EDUCATION REVITALIZATION ACT \n",
      "\n",
      "Top 4\n",
      " PRESCHOOL EDUCATION ACT \n",
      "\n",
      "Top 5\n",
      " EDUCATION REVITALIZATION ACT OF 2007 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Top {k} search results:\\n\\n')\n",
    "i = 1\n",
    "for title in bills['title'].iloc[search_results].to_list():\n",
    "    print(f'Top {i}\\n', title, '\\n')\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
